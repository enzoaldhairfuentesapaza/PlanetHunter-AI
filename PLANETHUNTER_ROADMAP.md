# PlanetHunter-AI ‚Äî Roadmap hacia un Multimodal Transformer (NASA Challenge)

> Objetivo: pasar del baseline RandomForest a un **Multimodal Transformer** que combine **tablas (KOI/TCE)** + **curvas de luz** y desplegar un **dashboard estilo Mission Control**.

## Fase 0 ‚Äî Endurecer baseline (1‚Äì2 d√≠as)
- [ ] Fijar semillas (`random_state=42`) en *train/test split*, `RandomForestClassifier`, y cualquier CV.
- [ ] A√±adir `class_weight="balanced"` al RF y reporte de **matriz de confusi√≥n** + **PR-AUC**.
- [ ] Guardar **umbral de decisi√≥n** para operar a **99% de precisi√≥n** y reportar *recall* a ese punto.
- [ ] Registrar versiones de datos y artefactos (MLflow/W&B o CSV en `data_science/reports/`).
- [ ] A√±adir tests b√°sicos con `pytest` (lectura KOI, split estratificado, shape de features).

## Fase 1 ‚Äî Datos y features (2‚Äì4 d√≠as)
- [ ] **Tablas (KOI/TCE):** normalizar, imputar NaNs, *label encode* de categor√≠as, *feature store* en Parquet.
- [ ] **Curvas de luz:** descargar de Kepler/TESS; *detrending* (Savitzky‚ÄìGolay, co-trending basis vectors), *folding* por periodo si aplica, *windowing* en eclipses.
- [ ] **Split sin fuga:** estratificar por etiqueta y **bloquear por estrella** (no mezclar el mismo objeto entre train/test).
- [ ] **Datasets balanceados:** *undersampling* controlado o *class weights*; opcional *focal loss* en DL.

## Fase 2 ‚Äî Unimodales (5‚Äì7 d√≠as)
- **TabTransformer (tabular)**
  - [ ] Encoder de columnas categ√≥ricas ‚Üí **embeddings** + bloques Transformer; num√©ricas ‚Üí *MLP/LayerNorm* y fusi√≥n.
  - [ ] Head MLP binaria con *BCEWithLogitsLoss* y *class weights*.
- **Time Series Transformer (curvas de luz)**
  - [ ] Tokens = muestras temporales; *positional encodings* + *padding mask* para longitudes variables.
  - [ ] Augmentations: *jittering*, *random cropping*, *time warping* leves.

> Entregar: dos modelos con **PR-AUC** y curvas precision‚Äìrecall; *recall @ 99% precision*.

## Fase 3 ‚Äî Multimodal (7‚Äì10 d√≠as)
Estrategias de fusi√≥n (empezar simple ‚Üí complejo):
1. **Late fusion:** combinar *logits* (promedio ponderado o *stacking* con un metaclassifier).
2. **Mid fusion (concat):** concatenar *[CLS]* del TS-Transformer + *[CLS]* del TabTransformer ‚Üí head MLP.
3. **Cross-attention:** usar *cross-modal attention* (el vector tabular consulta a la serie o viceversa).

- [ ] Entrenar las tres y comparar; elegir por **recall @ 99% precision** y **PR-AUC**.
- [ ] Calibraci√≥n de probabilidades (Platt/Isotonic).

## Fase 4 ‚Äî Evaluaci√≥n cient√≠fica (3‚Äì5 d√≠as)
- [ ] **Injection‚Äìrecovery tests**: inyectar tr√°nsitos sint√©ticos de diferente SNR, periodo y duraci√≥n; medir tasa de recuperaci√≥n.
- [ ] **Generalizaci√≥n entre misiones:** entrenar en Kepler, validar en TESS (2m y/o 30m).
- [ ] **Errores t√≠picos:** reporte de *top FN* y *top FP* con *light curve snippets*.
- [ ] **Interpretabilidad:**
  - Tabular: **SHAP** global/local, *permutation importance*.
  - Series: **Integrated Gradients** / *attention rollout* sobre ventanas de tr√°nsito.

## Fase 5 ‚Äî Dashboard estilo Mission Control (2‚Äì4 d√≠as)
**Stack sugerido:** Streamlit o Dash + Plotly.
- [ ] Panel de **KPIs**: Accuracy, Precision, Recall, F1, **PR-AUC**, y **recall @ P=0.99**.
- [ ] **Curvas de luz** con overlay del tr√°nsito y zonas de mayor atenci√≥n/IG.
- [ ] Tabla de candidatos con filtros (SNR, periodo, probabilidad, flags).
- [ ] Vista de **caso**: features tabulares + explicaci√≥n (SHAP) + se√±al cruda/procesada.
- [ ] **Animaciones**: 
  - Simulaci√≥n de ‚Äúse√±al de luz‚Äù pasando por el pipeline (frames/Plotly frames).
  - Evoluci√≥n del *training* (loss/PR-AUC vs epoch).

## Fase 6 ‚Äî MLOps / CI-CD (2‚Äì3 d√≠as)
- [ ] **DVC** o Git LFS para datos; *make targets* o `tox` para jobs (`make update-data`, `make train`, `make eval`).
- [ ] **GitHub Actions**: jobs separados para datos, train, tests y lint.
- [ ] Versionado de modelos (`data_science/models/`) + *model registry* simple (CSV + hash + fecha + m√©tricas).
- [ ] Semillas y `torch.backends.cudnn.deterministic=True` cuando aplique.

---

## Esqueleto de Modelo Multimodal (PyTorch)

```python
class TabEncoder(nn.Module):
    def __init__(self, emb_info, d_model=128, n_layers=2, n_heads=4):
        super().__init__()
        # emb_info: dict {col: (cardinality, emb_dim)}
        self.embs = nn.ModuleDict({c: nn.Embedding(card, dim) for c,(card,dim) in emb_info.items()})
        self.num_proj = nn.Sequential(nn.Linear(num_num_feats, d_model), nn.LayerNorm(d_model))
        encoder_layer = nn.TransformerEncoderLayer(d_model, n_heads, 4*d_model, batch_first=True)
        self.encoder = nn.TransformerEncoder(encoder_layer, n_layers)
        self.cls = nn.Parameter(torch.randn(1,1,d_model))
    def forward(self, x_cat, x_num):
        tokens = [emb(x_cat[c]) for c,emb in self.embs.items()]  # [B, Lc, d]
        num = self.num_proj(x_num).unsqueeze(1)                  # [B, 1, d]
        seq = torch.cat(tokens + [num], dim=1)                   # [B, Lt, d]
        cls = self.cls.expand(len(x_num), -1, -1)
        seq = torch.cat([cls, seq], dim=1)
        h = self.encoder(seq)[:,0]  # [CLS]
        return h

class TSencoder(nn.Module):
    def __init__(self, d_model=128, n_layers=4, n_heads=8):
        super().__init__()
        self.proj = nn.Linear(1, d_model)
        self.pos = PositionalEncoding(d_model)
        enc_layer = nn.TransformerEncoderLayer(d_model, n_heads, 4*d_model, batch_first=True)
        self.encoder = nn.TransformerEncoder(enc_layer, n_layers)
    def forward(self, x_ts, mask=None):          # x_ts: [B, T, 1]
        z = self.pos(self.proj(x_ts))
        h = self.encoder(z, src_key_padding_mask=mask)[:,0]  # usar primer token como [CLS]
        return h

class MultiModal(nn.Module):
    def __init__(self, tab_enc, ts_enc, d_model=128):
        super().__init__()
        self.tab = tab_enc
        self.ts  = ts_enc
        self.head = nn.Sequential(nn.Linear(2*d_model, d_model),
                                  nn.ReLU(),
                                  nn.Dropout(0.2),
                                  nn.Linear(d_model, 1))
    def forward(self, x_cat, x_num, x_ts, mask=None):
        h_tab = self.tab(x_cat, x_num)
        h_ts  = self.ts(x_ts, mask)
        h = torch.cat([h_tab, h_ts], dim=-1)
        return self.head(h).squeeze(-1)
```

> Entrenar con `BCEWithLogitsLoss(pos_weight=...)`, *scheduler* tipo OneCycle o Cosine, y evaluaci√≥n en cada epoch con **PR-AUC** + **recall @ P=0.99**.

---

## M√©tricas obligatorias a reportar
- Accuracy, Precision, Recall, F1 (macro/weighted).
- **PR-AUC** y **ROC-AUC**.
- **Recall @ 99% Precision** (operating point para minimizar FP).
- *Confusion matrix* y *Top FP/FN* con ejemplos.

---

## Pr√≥ximos pasos inmediatos (sugeridos)
- [ ] A√±adir `random_state` y `class_weight` al RF + matriz de confusi√≥n y PR-AUC.
- [ ] Definir `feature_spec.json` (categ√≥ricas con cardinalidad, num√©ricas con normalizaci√≥n).
- [ ] Prototipar el **TabTransformer** en un notebook y guardar baseline (artefacto + m√©tricas).
- [ ] Prototipar el **Time Series Transformer** con *folding* sobre tr√°nsitos.
- [ ] Implementar **late fusion** y comparar.
- [ ] Bosquejar **Dashboard (Streamlit)** con KPIs y vista de caso.

¬°√âxitos! üöÄ
